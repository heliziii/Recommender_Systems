{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e33be212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gzip\n",
    "from collections import defaultdict\n",
    "from sklearn import linear_model\n",
    "import csv\n",
    "import random\n",
    "import scipy\n",
    "import scipy.optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c10e101c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##reading data and forming validation set\n",
    "\n",
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)\n",
    "\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    c = csv.reader(f)\n",
    "    header = next(c)\n",
    "    for l in c:\n",
    "        d = dict(zip(header,l))\n",
    "        yield d['user_id'],d['recipe_id'],d['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3488c279",
   "metadata": {},
   "outputs": [],
   "source": [
    "totalCooked = 0\n",
    "train_set = []\n",
    "validation_set = []\n",
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)\n",
    "\n",
    "for user,recipe,rate in readCSV(\"trainInteractions.csv.gz\"):\n",
    "    totalCooked += 1\n",
    "    if totalCooked < 400000:\n",
    "        usersPerItem[recipe].add(user)\n",
    "        itemsPerUser[user].add(recipe)\n",
    "        r = int(rate)\n",
    "        allRatings.append(r)\n",
    "        train_set.append((user,recipe,rate))\n",
    "        userRatings[user].append(r)\n",
    "    if totalCooked >= 400000:\n",
    "        validation_set.append((user,recipe,rate))\n",
    "\n",
    "\n",
    "globalAverage = sum(allRatings) / len(allRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3232463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nUsers = len(itemsPerUser)\n",
    "nItems = len(usersPerItem)\n",
    "users = list(itemsPerUser.keys())\n",
    "items = list(usersPerItem.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "00ccd239",
   "metadata": {},
   "outputs": [],
   "source": [
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "cb5cc344",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "881ccba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(user, item):\n",
    "    return alpha + userBiases[user] + itemBiases[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1cf65d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(theta):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global itemBiases\n",
    "    alpha = theta[0]\n",
    "    userBiases = dict(zip(users, theta[1:nUsers+1]))\n",
    "    itemBiases = dict(zip(items, theta[1+nUsers:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "dbd0aac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    predictions = [prediction(d[0], d[1]) for d in train_set]\n",
    "    cost = MSE(predictions, labels)\n",
    "    print(\"MSE = \" + str(cost))\n",
    "    for u in userBiases:\n",
    "        cost += lamb*userBiases[u]**2\n",
    "    for i in itemBiases:\n",
    "        cost += lamb*itemBiases[i]**2\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "48bd9ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    N = len(train_set)\n",
    "    dalpha = 0\n",
    "    dUserBiases = defaultdict(float)\n",
    "    dItemBiases = defaultdict(float)\n",
    "    for d in train_set:\n",
    "        u,i = d[0], d[1]\n",
    "        pred = prediction(u, i)\n",
    "        diff = pred - int(d[2])\n",
    "        dalpha += 2/N*diff\n",
    "        dUserBiases[u] += 2/N*diff\n",
    "        dItemBiases[i] += 2/N*diff\n",
    "    for u in userBiases:\n",
    "        dUserBiases[u] += 2*lamb*userBiases[u]\n",
    "    for i in itemBiases:\n",
    "        dItemBiases[i] += 2*lamb*itemBiases[i]\n",
    "    dtheta = [dalpha] + [dUserBiases[u] for u in users] + [dItemBiases[i] for i in items]\n",
    "    return np.array(dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "93bea86d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.8987331675050297\n",
      "MSE = 0.8856375816231887\n",
      "MSE = 0.898597087332774\n",
      "MSE = 0.8985970389661542\n"
     ]
    }
   ],
   "source": [
    "x,f,d = scipy.optimize.fmin_l_bfgs_b(cost, [globalAverage] + [0.0]*(nUsers+nItems),\n",
    "                             derivative, args = (allRatings, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3ee7bf2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE on validation set = 0.9094351485419185\n"
     ]
    }
   ],
   "source": [
    "alpha = x[0]\n",
    "beta_u = x[1:nUsers+1]\n",
    "beta_i = x[nUsers+1:]\n",
    "ItemBiases = defaultdict(float)\n",
    "UserBiases = defaultdict(float)\n",
    "for i in range(len(users)):\n",
    "    UserBiases[users[i]] = beta_u[i]\n",
    "for i in range(len(items)):\n",
    "    UserBiases[items[i]] = beta_i[i]\n",
    "    \n",
    "validation_rates = [int(d[2]) for d in validation_set]\n",
    "    \n",
    "predicted = []\n",
    "for i in range(len(validation_set)):\n",
    "    user = validation_set[i][0]\n",
    "    item = validation_set[i][1]\n",
    "    rate = validation_set[1][2]\n",
    "    predicted.append(alpha + UserBiases[user] + ItemBiases[item])\n",
    "print(\"MSE on validation set = \" + str(MSE(predicted,validation_rates)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b6a9f5d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item with maximum bias = 76256724\n",
      "User with maximum bias = 32445558\n"
     ]
    }
   ],
   "source": [
    "print(\"Item with maximum bias = \" + str(max(ItemBiases, key=ItemBiases.get)))\n",
    "print(\"User with maximum bias = \" + str(max(UserBiases, key=UserBiases.get)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "380d7d48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.8987331675050297\n",
      "MSE = 0.8856375816231887\n",
      "MSE = 1.065441094811514\n",
      "MSE = 0.8838503954709337\n",
      "MSE = 0.8783967111041078\n",
      "MSE = 0.8774773515849977\n",
      "MSE = 0.8739924581177699\n",
      "MSE = 0.8608699675914993\n",
      "MSE = 0.8570189699934744\n",
      "MSE = 0.8538148221884256\n",
      "MSE = 0.8536452605109054\n",
      "MSE = 0.8537555501089433\n",
      "MSE = 0.8537338733728912\n",
      "MSE = 0.8536777631428745\n",
      "MSE = 0.8536423013761935\n",
      "MSE = 0.8536449724100961\n",
      "MSE = 0.8536446846701096\n",
      "MSE = 0.8536533746241003\n",
      "MSE = 0.8536447977761387\n",
      "MSE = 0.8987331675050297\n",
      "MSE = 0.8856375816231887\n",
      "MSE = 0.9657174700227784\n",
      "MSE = 0.8854124142437872\n",
      "MSE = 0.8896050307721269\n",
      "MSE = 0.888668918753176\n",
      "MSE = 0.8887459295308636\n",
      "MSE = 0.8887418924805084\n",
      "MSE = 0.8987331675050297\n",
      "MSE = 0.8856375816231887\n",
      "MSE = 0.8974328882737885\n",
      "MSE = 0.8975045743914509\n",
      "MSE = 0.8974282740439955\n",
      "MSE = 0.897428028896924\n",
      "MSE = 0.8974261102781619\n",
      "MSE = 0.8987331675050297\n",
      "MSE = 0.8856375816231887\n",
      "MSE = 0.898597087332774\n",
      "MSE = 0.8985970389661542\n",
      "MSE = 0.8987331675050297\n",
      "MSE = 0.8856375816231887\n",
      "MSE = 0.8987194962109345\n",
      "MSE = 0.8987194961482506\n",
      "MSE = 0.8987331675050297\n",
      "MSE = 0.8856375816231887\n",
      "MSE = 0.898731799744623\n",
      "0.8843835341075446 0.001\n"
     ]
    }
   ],
   "source": [
    "lambda_max = 0\n",
    "min_MSE = 1000\n",
    "for lambda_ in [0.001,0.01,0.1,1,10,100]:\n",
    "    x,f,d = scipy.optimize.fmin_l_bfgs_b(cost, [globalAverage] + [0.0]*(nUsers+nItems),\n",
    "                             derivative, args = (allRatings, lambda_))\n",
    "    alpha = x[0]\n",
    "    beta_u = x[1:nUsers+1]\n",
    "    beta_i = x[nUsers+1:]\n",
    "    ItemBiases = defaultdict(float)\n",
    "    UserBiases = defaultdict(float)\n",
    "    for i in range(len(users)):\n",
    "        UserBiases[users[i]] = beta_u[i]\n",
    "    for i in range(len(items)):\n",
    "        UserBiases[items[i]] = beta_i[i]\n",
    "\n",
    "    validation_rates = [int(d[2]) for d in validation_set]\n",
    "    predicted = []\n",
    "    for i in range(len(validation_set)):\n",
    "        user = validation_set[i][0]\n",
    "        item = validation_set[i][1]\n",
    "        rate = validation_set[1][2]\n",
    "        predicted.append(alpha + UserBiases[user] + ItemBiases[item])\n",
    "    MSE_lambda = MSE(predicted,validation_rates)\n",
    "    if MSE_lambda < min_MSE:\n",
    "        min_MSE = MSE_lambda\n",
    "        lambda_max = lambda_\n",
    "print(min_MSE, lambda_max)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975ace9f",
   "metadata": {},
   "source": [
    "Lambda value with minimum MSE is 0.001 and the MSE on validation set is 0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "18a7814a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 0.8987331675335475\n",
      "MSE = 0.885655711462093\n",
      "MSE = 1.0514168085665376\n",
      "MSE = 0.8837539762754325\n",
      "MSE = 0.8783964283627522\n",
      "MSE = 0.877529926025342\n",
      "MSE = 0.874233655552501\n",
      "MSE = 0.8610729138272688\n",
      "MSE = 0.8571565345207578\n",
      "MSE = 0.853888986826966\n",
      "MSE = 0.8536986822582134\n",
      "MSE = 0.8537676121195551\n",
      "MSE = 0.8537162316403992\n",
      "MSE = 0.8536691856933226\n",
      "MSE = 0.8536405044548784\n",
      "MSE = 0.8536393477099931\n",
      "MSE = 0.8536447848480913\n",
      "MSE = 0.8536399918702993\n",
      "MSE = 0.8536441752771732\n",
      "MSE = 0.853644647974439\n",
      "MSE = 0.8536446551261031\n"
     ]
    }
   ],
   "source": [
    "allRatings = []\n",
    "userRatings = defaultdict(list)\n",
    "usersPerItem = defaultdict(set)\n",
    "itemsPerUser = defaultdict(set)\n",
    "\n",
    "\n",
    "for user,recipe,rate in readCSV(\"trainInteractions.csv.gz\"):\n",
    "    usersPerItem[recipe].add(user)\n",
    "    itemsPerUser[user].add(recipe)\n",
    "    r = int(rate)\n",
    "    allRatings.append(r)\n",
    "\n",
    "globalAverage = sum(allRatings) / len(allRatings)\n",
    "\n",
    "nUsers = len(itemsPerUser)\n",
    "nItems = len(usersPerItem)\n",
    "users = list(itemsPerUser.keys())\n",
    "items = list(usersPerItem.keys())\n",
    "    \n",
    "x,f,d = scipy.optimize.fmin_l_bfgs_b(cost, [globalAverage] + [0.0]*(nUsers+nItems),\n",
    "                             derivative, args = (allRatings, 0.001))\n",
    "\n",
    "alpha = x[0]\n",
    "beta_u = x[1:nUsers+1]\n",
    "beta_i = x[nUsers+1:]\n",
    "ItemBiases = defaultdict(float)\n",
    "UserBiases = defaultdict(float)\n",
    "for i in range(len(users)):\n",
    "    UserBiases[users[i]] = beta_u[i]\n",
    "for i in range(len(items)):\n",
    "    UserBiases[items[i]] = beta_i[i]\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c5cfeef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = open(\"predictions_Rated.txt\", 'w')\n",
    "for l in open(\"stub_Rated.txt\"):\n",
    "    if l.startswith(\"user_id\"):\n",
    "        #header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,i = l.strip().split('-')\n",
    "    if (u not in users) and (i not in items):\n",
    "        predictions.write(u + '-' + i + ',' + str(alpha) + '\\n')\n",
    "    elif (u not in users):\n",
    "        predictions.write(u + '-' + i + ',' + str(alpha + ItemBiases[i]) + '\\n')\n",
    "    elif (i not in items):\n",
    "        predictions.write(u + '-' + i + ',' + str(alpha + UserBiases[u]) + '\\n')\n",
    "    elif (i in items) and (u in users):\n",
    "        predictions.write(u + '-' + i + ',' + str(alpha + UserBiases[u] + ItemBiases[i]) + '\\n')\n",
    "\n",
    "    \n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf958f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
